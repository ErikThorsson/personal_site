<div class="row col-12 no-gutters text-center intro">
    <div class="col-8 offset-2">
        <span>Automate Everything.</span>
    </div>
</div>

<div class="row col-12 no-gutters text-center mainBox">

    <br><br>
    <div class="col-12 text-center">
        <div class="col-12 tile">
            <div class="text-left">June 23, 2018</div>
            <header class="title">Explorations with the Intel RealSense D415 Depth Camera.</header>
            <span><br>Unfiltered depth video in the coffee shop.</span>
            <div class="col-6 offset-3">
                <div class="vid-container">
                    <iframe src="https://www.youtube.com/embed/mXSlDmlVsXc"
                            frameborder="0" allowfullscreen>
                    </iframe>
                </div>
            </div>
            <br>
            <div class="col-12 col-lg-10 offset-lg-1 text-left">
                <br>
                Here we have a generic video feed from the camera using the camera's own software. You can see some noise
                in the first half of the video before I switch to high accuracy mode which creates more black holes with 0 depth
                but the ones that are returned have higher confidence.
                <br><br>
                This isn't too exciting though as this camera is made for devs...
                so lets crack the code open and make some custom software with the RealSense sdk and opencv using the python wrapper!
                This is the main loop where we can separate the depth frame from the RGB frame for post processing.
            </div>
            <br>
            <div class="col-12 col-lg-6 offset-lg-3 text-left">
                <blockquote><pre><code class="code">
      import pyrealsense2 as rs
      import cv2 as cv
      import numpy as np

        def runPipeline():
          start = timeit.default_timer()
          pipeline = rs.pipeline()

          config = rs.config()
          config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)
          config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
          config.resolve(pipeline)
          pipeline.start(config)  # Start streaming

          cv.namedWindow("viewer")
          try:
              while True:
                  frames = pipeline.wait_for_frames()
                  depth_frame = frames.get_depth_frame()
                  color_frame = frames.get_color_frame()
                    if not depth_frame or not color_frame:
                       continue

                  # Convert images to numpy arrays
                  color_image = np.asanyarray(color_frame.get_data())
                  depth_image = np.asanyarray(depth_frame.get_data())
                  depth_colormap = cv.applyColorMap(cv.convertScaleAbs(depth_image, alpha=0.03), cv.COLORMAP_JET)

                  cv.imshow('viewer', depth_colormap)
                  cv.waitKey(1)

          finally:
              pipeline.stop()
      </code></pre></blockquote></div>
            <br>
            <div class="col-12 col-lg-10 offset-lg-1 text-left">
                This next method filters the image using the depth values. The depth image's data is taken from its numpy array and then the
                pixel depth value is found using a constant from the sdk.
                <br><br>
                We assign white pixels to any depth value that is .6 in above the floor to remove noise. What is considered the floor
                is painted black. We skip every 5 pixels to speed up the processing.
            </div>
            <br>
            <div class="col-12 col-lg-6 offset-lg-3 text-left">
                <blockquote><pre><code class="code">
          def filter_depth(depth_image, color_image):
              DEPTH_SCALE = .0010000000474974513
              #box around objects for faster processing
              X_RIGHT = 790
              X_LEFT = 500
              Y_TOP = 250
              Y_BOTTOM = 475

              #color the floor  black, and the objects white
              for y in range(Y_TOP, Y_BOTTOM, 5):
                  for x in range(X_LEFT, X_RIGHT, 5):
                      data = np.fromstring(depth_image[y, x], dtype=np.uint16)
                      data = np.array(data, dtype=float)
                      depth_value = data * DEPTH_SCALE
                          # The only real depth variables we are concerned with are the objects, so we will try to filter the floor values out.
                          # If the depth is less than 0.6 inches in difference from the floor depth constant paint it black. Else, white.
                      if(FLOOR_DEPTH - depth_value < 0.015) or depth_value == 0:
                          color_image[y][x] = [0,0,0] #black
                      else:
                          color_image[y][x] = [255,255,255] #white
              return color_image
      </code></pre></blockquote></div>
            <br>
            <div class="col-12 col-lg-10 offset-lg-1 text-left">
                We want to further filter the image now though. so we will be using some opencv. Our filtering into white and black
                will make it easier to find object outlines, or contours.
                If we don't skip pixels the above code will find contours of all white shapes and highlight around object "blobs".
                Otherwise, it will create a cool neon circle effect around the white pixels.
            </div>
            <div class="col-12 col-lg-6 offset-lg-3 text-left">
                <blockquote><pre><code class="code">
            # find all the 'white' shapes in the image
            lower = np.array([255, 255, 255])
            upper = np.array([255, 255, 255])
            shapeMask = cv.inRange(image, lower, upper)

            # find the contours in the mask
            _, cnts, _ = cv.findContours(shapeMask.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)

            # loop over the contours
            for c in cnts:
                # draw the contour and show it
                cv.drawContours(image, [c], -1, (0, 255, 0), 2)
      </code></pre></blockquote></div>
            <span><br>Looking at the depth of a box through our filter.</span>
            <div class="col-6 offset-3">
                <div class="vid-container">
                    <iframe src="https://www.youtube.com/embed/VNaVkOVCamM"
                            frameborder="0" allowfullscreen>
                    </iframe>
                </div>
            </div>
            <br><br>
            <div class="col-12 col-lg-10 offset-lg-1 text-left">
                Next we can add rudimentary object detection and counting using an image recognition library called sci-kit.
                This library will attempt to find "blobs", and then our next function will try to group them by radius size 25% of
                each other.
            </div>
            <div class="col-12 col-lg-6 offset-lg-3 text-left">
                <blockquote><pre><code class="code">
          from math import sqrt
          from skimage.feature import blob_dog, blob_log, blob_doh
          from skimage.color import rgb2gray

          def blob(image):
            image_gray = rgb2gray(image)

            blobs_dog = blob_dog(image_gray, max_sigma=30, threshold=.1)
            blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)

            blobs_list = [blobs_dog]

            colors = ['red']
            titles = ['Difference of Gaussian']
            sequence = zip(blobs_list, colors, titles)

            fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)
            ax = axes.ravel()

            for idx, (blobs, color, title) in enumerate(sequence):
                ax[idx].set_title(title)
                ax[idx].imshow(image, interpolation='nearest')
                for blob in blobs:
                    y, x, r = blob
                    c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)
                    ax[idx].add_patch(c)
                ax[idx].set_axis_off()

            radiuses = []

            for blob in blobs:
                y, x, r = blob
                radiuses.append(r)

            radiuses.sort()
            result = get_blocks(radiuses)
            print(result)

            for r in result:
                print(str(len(r)) + " objects of close radius to " + str(r[0]) + " found.");
            plt.tight_layout()
            plt.show()

      #https://stackoverflow.com/questions/23541567/find-numbers-in-python-list-which-are-within-a-certain-distance-of-each-other
      #groups objects that are 25% of each other
      def get_blocks(values):
          mi, ma = 0, 0
          result = []
          temp = []
          for v in sorted(values):
              if not temp:
                  mi = ma = v
                  temp.append(v)
              else:
                  if ((abs(mi - v) / mi) * 100 <= 25) and ((abs(ma - v) / ma) * 100 <= 25):
                      temp.append(v)
                      if v < mi:
                          mi = v
                      elif v > ma:
                          ma = v
                  else:
                      if len(temp) > 1:
                          result.append(temp)
                      mi = ma = v
                      temp = [v]
          result.append(temp)
          return result
      </code></pre></blockquote></div>
            <span><br>ReaSense box and inner package --> Filtered detection.</span><br>
            <div class="col-6 offset-3">
                <div class="row">
                    <img class="box-img col-6" src="rs-save-to-disk-output-Color.png"/>
                    <img class="box-img col-6" src="blobs.png"/>
                </div>
            </div>
            <br>
            <div class="col-12 col-lg-10 offset-lg-1 text-left">
                <br>
                [[37.96250624970064, 37.96250624970064]]
                2 objects of close radius to 37.96250624970064 found.
            </div>
        </div>
        <div class="col-12 tile bottom">
            <a href="https://github.com/ErikThorsson" class="col-12">https://github.com/ErikThorsson</a>
        </div>
    </div>
</div>

<div class="col-12 row contact">
    <div class="col-4 text-center">
        <br>
        eorndahl@gmail.com
    </div>
    <div class="col-4 text-center">
        <br>
        404-550-5358
    </div>
    <div class="col-4 text-center">
        <br>
        Powered by <a href="https://github.com/ngx-rocket">ngX-rocket</a>
        <img class="logo" src="ngx-rocket-logo.png" alt="angular logo"/>
    </div>
</div>




